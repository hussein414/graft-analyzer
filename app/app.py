# app/app.py
import os, sys, io, base64
from typing import Dict
import streamlit as st
from PIL import Image

# import core/*
ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))
if ROOT not in sys.path:
    sys.path.insert(0, ROOT)

from core.graft_counter import count_grafts
from core.ml_infer import detect_accelerators
import cv2
import numpy as np

st.set_page_config(page_title="Graft Analyzer", layout="wide")
st.title("ğŸ§ª Graft Analyzer â€” Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡")

# --- Sidebar ---
st.sidebar.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª")

# Ø§Ù†ØªØ®Ø§Ø¨ Preset
preset_option = st.sidebar.selectbox(
    "ğŸ¯ Preset",
    ["clientdemo", "ultra_dense", "aggressive", "qc"],  # â† Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù… aggressive
    help="clientdemo: Ø¹Ø§Ø¯ÛŒ | ultra_dense: ØªØ±Ø§Ú©Ù… Ø¨Ø§Ù„Ø§ | aggressive: Ø®ÛŒÙ„ÛŒ Ø­Ø³Ø§Ø³ | qc: Ú©Ù†ØªØ±Ù„ Ú©ÛŒÙÛŒØª"
)
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡
with st.sidebar.expander("ğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)"):
    st.info("Ø§Ú¯Ù‡ Ù†ØªÛŒØ¬Ù‡ Ø®ÙˆØ¨ Ù†Ø¨ÙˆØ¯ØŒ Ø§ÛŒÙ†Ø§ Ø±Ùˆ ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡")

    use_custom = st.checkbox("Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø³ØªÛŒ", value=False)

    if use_custom:
        adapt_block = st.slider("Adaptive Block", 11, 91, 31, step=2)
        adapt_C = st.slider("Adaptive C", -20, 0, -8)
        watershed_ratio = st.slider("Watershed Ratio", 0.3, 0.8, 0.5, step=0.05)
        min_size = st.slider("Ø­Ø¯Ø§Ù‚Ù„ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú¯Ø±Ø§ÙØª", 1.0, 10.0, 3.0, step=0.5)
        max_size = st.slider("Ø­Ø¯Ø§Ú©Ø«Ø± Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú¯Ø±Ø§ÙØª", 20.0, 80.0, 40.0, step=5.0)
    else:
        adapt_block = None
        adapt_C = None
        watershed_ratio = None
        min_size = None
        max_size = None

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ’» Hardware")
st.sidebar.write(detect_accelerators())


# --- Helpers ---
def _show_overlay_from_b64(b64: str, caption: str):
    if not b64:
        st.warning("Ø®Ø±ÙˆØ¬ÛŒ ØªØµÙˆÛŒØ±ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return
    data = base64.b64decode(b64)
    img = Image.open(io.BytesIO(data)).convert("RGB")
    st.image(img, caption=caption, use_column_width=True)


def _img_to_b64(img_rgb: np.ndarray) -> str:
    """ØªØ¨Ø¯ÛŒÙ„ numpy array Ø¨Ù‡ base64"""
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    ok, buf = cv2.imencode(".jpg", img_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), 90])
    if not ok:
        return ""
    return base64.b64encode(buf.tobytes()).decode("ascii")


def analyze_with_params(img_bgr, preset, custom_params=None):
    """ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…"""
    if custom_params and custom_params.get("use_custom"):
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ
        from core.graft_counter import Preset
        custom_preset = Preset(
            spec_quantile=99.8,
            log_sigmas=(1.5, 2.5, 3.5, 5.0),
            adapt_block=custom_params.get("adapt_block", 31),
            adapt_C=custom_params.get("adapt_C", -8),
            watershed_peak_ratio=custom_params.get("watershed_ratio", 0.5),
            elong_max=5.0,
            circ_min=0.05,
            th_min_px=custom_params.get("min_size", 3.0),
            th_max_px=custom_params.get("max_size", 40.0),
            tophat_kernel=25,
        )

        # Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø§ preset Ø³ÙØ§Ø±Ø´ÛŒ
        from core.graft_counter import _detect_petri_dish_mask, _specular_keep_mask
        from core.graft_counter import _log_multiscale_response, _watershed_split
        from core.graft_counter import _measure_and_filter

        P = custom_preset
        dish_mask = _detect_petri_dish_mask(img_bgr)
        keep = _specular_keep_mask(img_bgr, P.spec_quantile)

        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
        gray = clahe.apply(gray)

        ksize = P.tophat_kernel | 1
        toph = cv2.morphologyEx(
            gray, cv2.MORPH_TOPHAT,
            cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ksize, ksize))
        )

        logmax = _log_multiscale_response(toph, P.log_sigmas)
        cand = cv2.adaptiveThreshold(logmax, 255,
                                     cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                     cv2.THRESH_BINARY,
                                     P.adapt_block, P.adapt_C)

        cand = cv2.bitwise_and(cand, dish_mask)
        cand = cv2.bitwise_and(cand, keep)
        cand = cv2.morphologyEx(cand, cv2.MORPH_OPEN,
                                cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)), 1)
        cand = cv2.morphologyEx(cand, cv2.MORPH_CLOSE,
                                cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)), 2)

        labels_ws = _watershed_split(cand, P.watershed_peak_ratio)
        num, lbl, stats, cent = cv2.connectedComponentsWithStats(labels_ws, 8)

        accepted_pts, rejected_pts = _measure_and_filter(
            lbl, stats, cent,
            P.th_min_px, P.th_max_px,
            P.elong_max, P.circ_min
        )

        # Ø±Ø³Ù…
        rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        overlay_clean = rgb.copy()
        overlay_debug = rgb.copy()

        contours, _ = cv2.findContours(dish_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(overlay_clean, contours, -1, (0, 255, 0), 3)
        cv2.drawContours(overlay_debug, contours, -1, (0, 255, 0), 3)

        for (x, y) in accepted_pts:
            cv2.circle(overlay_clean, (int(x), int(y)), 5, (255, 0, 0), -1)
            cv2.circle(overlay_debug, (int(x), int(y)), 5, (255, 0, 0), -1)

        for (x, y) in rejected_pts:
            cv2.circle(overlay_debug, (int(x), int(y)), 3, (255, 255, 0), -1)

        return {
            "count": len(accepted_pts),
            "points": np.array(accepted_pts),
            "rejected_points": np.array(rejected_pts),
            "overlay_clean": overlay_clean,
            "overlay_debug": overlay_debug,
            "preset": "custom"
        }
    else:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² preset Ù…Ø¹Ù…ÙˆÙ„ÛŒ
        return count_grafts(img_bgr, preset=preset)


# --- Main ---
st.markdown("### ğŸ“¤ Ø¢Ù¾Ù„ÙˆØ¯ ØªØµÙˆÛŒØ±")
uploaded = st.file_uploader("ØªØµÙˆÛŒØ± Ø¸Ø±Ù Ù¾ØªØ±ÛŒ Ø±Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†", type=["jpg", "jpeg", "png", "bmp", "tif", "tiff"])

if uploaded:
    # Ù†Ù…Ø§ÛŒØ´ ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("ğŸ–¼ï¸ ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ")
        original_img = Image.open(uploaded)
        st.image(original_img, use_column_width=True)

    with col2:
        st.subheader("â„¹ï¸ Ø§Ø·Ù„Ø§Ø¹Ø§Øª")
        st.info(f"""
        **Ù†Ø§Ù… ÙØ§ÛŒÙ„:** {uploaded.name}
        **Ø§Ù†Ø¯Ø§Ø²Ù‡:** {uploaded.size / 1024:.1f} KB
        **Preset Ø§Ù†ØªØ®Ø§Ø¨ÛŒ:** {preset_option}
        """)

        # Ø¯Ú©Ù…Ù‡ ØªØ­Ù„ÛŒÙ„
        analyze_btn = st.button("ğŸ” Ø´Ù…Ø§Ø±Ø´ Ú¯Ø±Ø§ÙØªâ€ŒÙ‡Ø§", type="primary", use_container_width=True)

    # Ø§Ú¯Ù‡ Ø¯Ú©Ù…Ù‡ Ø²Ø¯Ù‡ Ø´Ø¯
    if analyze_btn:
        with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„..."):
            try:
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ numpy
                img_pil = Image.open(uploaded).convert("RGB")
                img_rgb = np.array(img_pil)
                img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

                # ØªØ­Ù„ÛŒÙ„
                custom_params = None
                if use_custom:
                    custom_params = {
                        "use_custom": True,
                        "adapt_block": adapt_block,
                        "adapt_C": adapt_C,
                        "watershed_ratio": watershed_ratio,
                        "min_size": min_size,
                        "max_size": max_size
                    }

                result = analyze_with_params(img_bgr, preset_option, custom_params)

                # Ù†Ù…Ø§ÛŒØ´ Ù†ØªÛŒØ¬Ù‡
                st.markdown("---")
                st.success(f"âœ… **ØªØ¹Ø¯Ø§Ø¯ Ú¯Ø±Ø§ÙØªâ€ŒÙ‡Ø§: {result['count']}**")

                # ØªØ¨â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
                tab1, tab2, tab3 = st.tabs(["ğŸ¯ Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ", "ğŸ” Ø¬Ø²Ø¦ÛŒØ§Øª (Debug)", "ğŸ“Š Ø§Ø·Ù„Ø§Ø¹Ø§Øª"])

                with tab1:
                    overlay_clean_b64 = _img_to_b64(result["overlay_clean"])
                    _show_overlay_from_b64(overlay_clean_b64, "Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ")

                with tab2:
                    overlay_debug_b64 = _img_to_b64(result["overlay_debug"])
                    _show_overlay_from_b64(overlay_debug_b64, "Debug (Ù‚Ø±Ù…Ø²=Ù‚Ø¨ÙˆÙ„ Ø´Ø¯Ù‡ØŒ Ø²Ø±Ø¯=Ø±Ø¯ Ø´Ø¯Ù‡)")

                    if "rejected_points" in result:
                        rejected_count = len(result["rejected_points"])
                        st.warning(f"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù‚Ø§Ø· Ø±Ø¯ Ø´Ø¯Ù‡: {rejected_count}")

                with tab3:
                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.metric("âœ… Ù‚Ø¨ÙˆÙ„ Ø´Ø¯Ù‡", result["count"])
                    with col_b:
                        if "rejected_points" in result:
                            st.metric("âŒ Ø±Ø¯ Ø´Ø¯Ù‡", len(result["rejected_points"]))

                    st.json({
                        "preset": result.get("preset", preset_option),
                        "total_detected": result["count"] + len(result.get("rejected_points", [])),
                        "accepted": result["count"],
                        "rejected": len(result.get("rejected_points", []))
                    })

                # Ø¯Ú©Ù…Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯
                st.markdown("---")
                result_img = cv2.cvtColor(result["overlay_clean"], cv2.COLOR_RGB2BGR)
                _, buf = cv2.imencode('.jpg', result_img)
                st.download_button(
                    label="ğŸ’¾ Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± Ù†ØªÛŒØ¬Ù‡",
                    data=buf.tobytes(),
                    file_name=f"result_{uploaded.name}",
                    mime="image/jpeg"
                )

            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}")
                st.exception(e)
else:
    st.info("ğŸ‘† ÛŒÙ‡ ØªØµÙˆÛŒØ± Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù† ØªØ§ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒÙ…")

    # Ø±Ø§Ù‡Ù†Ù…Ø§
    with st.expander("ğŸ“– Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡"):
        st.markdown("""
        ### Ú†Ø·ÙˆØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ù…ØŸ

        1. **Ø¢Ù¾Ù„ÙˆØ¯ ØªØµÙˆÛŒØ±** ğŸ“¤
           - ÛŒÙ‡ Ø¹Ú©Ø³ Ø§Ø² Ø¸Ø±Ù Ù¾ØªØ±ÛŒ Ø±Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†

        2. **Ø§Ù†ØªØ®Ø§Ø¨ Preset** ğŸ¯
           - **clientdemo**: Ø¨Ø±Ø§ÛŒ Ø¹Ú©Ø³â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ
           - **ultra_dense**: Ø¨Ø±Ø§ÛŒ Ú¯Ø±Ø§ÙØªâ€ŒÙ‡Ø§ÛŒ Ø®ÛŒÙ„ÛŒ Ø²ÛŒØ§Ø¯ (Ù…Ø«Ù„ Ø¹Ú©Ø³ ØªÙˆ!)
           - **qc**: Ø¨Ø±Ø§ÛŒ Ú©Ù†ØªØ±Ù„ Ú©ÛŒÙÛŒØª

        3. **ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡** (Ø§Ø®ØªÛŒØ§Ø±ÛŒ) ğŸ”§
           - Ø§Ú¯Ù‡ Ù†ØªÛŒØ¬Ù‡ Ø®ÙˆØ¨ Ù†Ø¨ÙˆØ¯ØŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ùˆ Ø¨Ø§Ø² Ú©Ù†
           - Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø±Ùˆ ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡ Ùˆ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªØ³Øª Ú©Ù†

        4. **Ø´Ù…Ø§Ø±Ø´** ğŸ”
           - Ø¯Ú©Ù…Ù‡ "Ø´Ù…Ø§Ø±Ø´ Ú¯Ø±Ø§ÙØªâ€ŒÙ‡Ø§" Ø±Ùˆ Ø¨Ø²Ù†
           - ØµØ¨Ø± Ú©Ù† ØªØ§ ØªØ­Ù„ÛŒÙ„ ØªÙ…ÙˆÙ… Ø¨Ø´Ù‡

        5. **Ø¨Ø±Ø±Ø³ÛŒ Ù†ØªÛŒØ¬Ù‡** âœ…
           - ØªØ¨ "Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ" Ø±Ùˆ Ø¨Ø¨ÛŒÙ†
           - Ø§Ú¯Ù‡ Ù…Ø´Ú©Ù„ Ø¯Ø§Ø´ØªØŒ ØªØ¨ "Debug" Ø±Ùˆ Ø¨Ø¨ÛŒÙ†
           - Ù†Ù‚Ø§Ø· Ø²Ø±Ø¯ = Ø±Ø¯ Ø´Ø¯Ù‡ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø§Ø´ØªØ¨Ø§Ù‡ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡)

        ### Ù†Ú©Ø§Øª Ù…Ù‡Ù…:
        - Ø¨Ø±Ø§ÛŒ Ø¹Ú©Ø³â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø«Ù„ Ø¹Ú©Ø³ ØªÙˆØŒ **ultra_dense** Ø±Ùˆ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†
        - Ø§Ú¯Ù‡ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù… Ø´Ù…Ø§Ø±Ø´ Ø´Ø¯ØŒ slider Ù‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø±Ùˆ ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡
        - Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ù†ØªÛŒØ¬Ù‡ Ø±Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒ
        """)

st.markdown("---")
st.caption("Â© Graft Analyzer â€” Ù†Ø³Ø®Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª")