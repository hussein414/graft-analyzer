# core/sam_detector.py
"""
Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SAM (Segment Anything Model) Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø¨Ø¯ÙˆÙ† Ø¢Ù…ÙˆØ²Ø´
Ù†ÛŒØ§Ø²: pip install segment-anything-fast
"""
import cv2
import numpy as np
from typing import Dict, List, Tuple

def detect_with_sam(image_bgr: np.ndarray) -> Dict:
    """
    Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SAM Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ú¯Ø±Ø§ÙØªâ€ŒÙ‡Ø§
    
    Ù…Ø²Ø§ÛŒØ§:
    - Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´
    - Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ (80-90%)
    - Ø³Ø±ÛŒØ¹
    """
    try:
        from segment_anything import sam_model_registry, SamAutomaticMaskGenerator
    except ImportError:
        print("âŒ SAM Ù†ØµØ¨ Ù†ÛŒØ³Øª!")
        print("Ù†ØµØ¨: pip install git+https://github.com/facebookresearch/segment-anything.git")
        return {"error": "SAM not installed"}
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ (Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø± Ú©Ù…ÛŒ Ø·ÙˆÙ„ Ù…ÛŒâ€ŒÚ©Ø´Ù‡)
    print("ğŸ¤– Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ SAM...")
    sam_checkpoint = "sam_vit_b_01ec64.pth"  # Ù…Ø¯Ù„ base (Ú©ÙˆÚ†Ú©ØªØ±)
    model_type = "vit_b"
    device = "cuda" if cv2.cuda.getCudaEnabledDeviceCount() > 0 else "cpu"
    
    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
    sam.to(device=device)
    
    mask_generator = SamAutomaticMaskGenerator(
        model=sam,
        points_per_side=32,
        pred_iou_thresh=0.86,
        stability_score_thresh=0.92,
        crop_n_layers=1,
        crop_n_points_downscale_factor=2,
        min_mask_region_area=100,  # Ø­Ø¯Ø§Ù‚Ù„ Ø§Ù†Ø¯Ø§Ø²Ù‡
    )
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ RGB
    rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    
    print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ ØªØ´Ø®ÛŒØµ...")
    masks = mask_generator.generate(rgb)
    
    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§
    centers = []
    boxes = []
    
    for mask in masks:
        # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù†Ø¯Ø§Ø²Ù‡
        area = mask['area']
        if area < 50 or area > 5000:  # ØªÙ†Ø¸ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§ÛŒØ² Ú¯Ø±Ø§ÙØª
            continue
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø±Ú©Ø²
        segmentation = mask['segmentation']
        y_coords, x_coords = np.where(segmentation)
        if len(x_coords) == 0:
            continue
        
        cx = int(x_coords.mean())
        cy = int(y_coords.mean())
        
        # Bounding box
        x_min, x_max = x_coords.min(), x_coords.max()
        y_min, y_max = y_coords.min(), y_coords.max()
        
        centers.append((cx, cy))
        boxes.append((int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)))
    
    # Ø±Ø³Ù… Ù†ØªØ§ÛŒØ¬
    overlay = image_bgr.copy()
    for (cx, cy) in centers:
        cv2.circle(overlay, (cx, cy), 5, (0, 0, 255), -1)
    
    for (x, y, w, h) in boxes:
        cv2.rectangle(overlay, (x, y), (x + w, y + h), (0, 255, 0), 1)
    
    return {
        "count": len(centers),
        "centers": centers,
        "boxes": boxes,
        "chosen": "sam",
        "overlay_bgr": overlay,
    }

def detect_simple_sam(image_bgr: np.ndarray) -> Dict:
    """
    Ù†Ø³Ø®Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØªØ± - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² contour detection Ù‡ÙˆØ´Ù…Ù†Ø¯
    Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ SAM (Ø¨Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¶Ø¹ÛŒÙ)
    """
    from core.dish import detect_petri_mask
    
    # Ù…Ø§Ø³Ú© Ø¸Ø±Ù
    dish_mask, _ = detect_petri_mask(image_bgr, erode_px=30)
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ grayscale
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    
    # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù‚ÙˆÛŒ
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    gray = clahe.apply(gray)
    
    # Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Otsu
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    binary = cv2.bitwise_and(binary, dish_mask)
    
    # Ù…ÙˆØ±ÙÙˆÙ„ÙˆÚ˜ÛŒ
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)
    
    # Distance transform + watershed
    dist = cv2.distanceTransform(binary, cv2.DIST_L2, 5)
    _, sure_fg = cv2.threshold(dist, 0.3 * dist.max(), 255, 0)
    sure_fg = np.uint8(sure_fg)
    
    # Connected components
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(sure_fg, connectivity=8)
    
    # ÙÛŒÙ„ØªØ±
    centers = []
    boxes = []
    
    for i in range(1, num_labels):
        area = stats[i, cv2.CC_STAT_AREA]
        if area < 30 or area > 3000:
            continue
        
        cx, cy = int(centroids[i][0]), int(centroids[i][1])
        x, y = stats[i, cv2.CC_STAT_LEFT], stats[i, cv2.CC_STAT_TOP]
        w, h = stats[i, cv2.CC_STAT_WIDTH], stats[i, cv2.CC_STAT_HEIGHT]
        
        centers.append((cx, cy))
        boxes.append((x, y, w, h))
    
    # Ø±Ø³Ù…
    overlay = image_bgr.copy()
    for (cx, cy) in centers:
        cv2.circle(overlay, (cx, cy), 4, (0, 0, 255), -1)
    
    return {
        "count": len(centers),
        "centers": centers,
        "boxes": boxes,
        "chosen": "simple_sam",
        "overlay_bgr": overlay,
    }
